{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV9NdqOb69Ql"
      },
      "source": [
        "# SetUp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_FkFMB_EhyM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "import zepid\n",
        "from zepid import load_sample_data\n",
        "from zepid.causal.ipw import IPTW\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# step 1 and step 2 Setup and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COoqPtol69Qo",
        "outputId": "9551c6bb-392c-4412-ff8c-d672d8096f4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "## Trial Sequence Object\n",
            "## Estimand: ITT\n",
            "\n",
            "## Data:\n",
            " - N: 725 observations from 89 patients\n",
            "\n",
            "Data Preview:\n",
            "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  censored  eligible\n",
            "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0         0         1\n",
            "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0         0         0\n",
            "---\n",
            "     id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  censored  eligible\n",
            "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000        0         0         0\n",
            "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333        1         0         0\n",
            "\n",
            "Variable Types:\n",
            "id             int64\n",
            "period         int64\n",
            "treatment      int64\n",
            "x1             int64\n",
            "x2           float64\n",
            "x3             int64\n",
            "x4           float64\n",
            "age            int64\n",
            "age_s        float64\n",
            "outcome        int64\n",
            "censored       int64\n",
            "eligible       int64\n",
            "\n",
            "## IPW for informative censoring:\n",
            " - No weight model specified\n",
            "\n",
            "## Sequence of Trials Data:\n",
            " - Use set_expansion_options() and expand_trials() to construct the sequence of trials dataset.\n",
            "\n",
            "## Outcome model:\n",
            " - Not specified\n",
            "##################################################\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def trial_sequence(estimand):\n",
        "    \"\"\"Initialize a trial sequence with specified estimand.\"\"\"\n",
        "    return {\n",
        "        \"estimand\": estimand,\n",
        "        \"data\": None,\n",
        "        \"ipw_model\": None,\n",
        "        \"outcome_model\": None\n",
        "    }\n",
        "\n",
        "def set_data(trial, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
        "    \"\"\"Prepare and store trial data with relevant columns.\"\"\"\n",
        "    trial[\"data\"] = data[\n",
        "        [id_col, period_col, treatment_col, \"x1\", \"x2\", \"x3\", \"x4\",\n",
        "         \"age\", \"age_s\", outcome_col, \"censored\", eligible_col]\n",
        "    ].copy()\n",
        "    return trial\n",
        "\n",
        "def summarize_trial(trial):\n",
        "    \"\"\"Print a structured summary of the trial object.\"\"\"\n",
        "    print(f\"## Trial Sequence Object\")\n",
        "    print(f\"## Estimand: {trial['estimand']}\\n\")\n",
        "\n",
        "    print(\"## Data:\")\n",
        "    data = trial[\"data\"]\n",
        "    if data is not None:\n",
        "        n_obs = len(data)\n",
        "        n_patients = data[\"id\"].nunique()\n",
        "        print(f\" - N: {n_obs} observations from {n_patients} patients\")\n",
        "\n",
        "        print(\"\\nData Preview:\")\n",
        "        with pd.option_context('display.max_columns', None, 'display.expand_frame_repr', False):\n",
        "            print(data.head(2).to_string())\n",
        "            print(\"---\")\n",
        "            print(data.tail(2).to_string())\n",
        "\n",
        "        print(\"\\nVariable Types:\")\n",
        "        print(data.dtypes.to_string())\n",
        "    else:\n",
        "        print(\" - No data loaded\")\n",
        "\n",
        "    print(\"\\n## IPW for informative censoring:\")\n",
        "    print(\" - No weight model specified\" if trial[\"ipw_model\"] is None\n",
        "          else f\" - Model: {trial['ipw_model']}\")\n",
        "\n",
        "    print(\"\\n## Sequence of Trials Data:\")\n",
        "    print(\" - Use set_expansion_options() and expand_trials() to construct the sequence of trials dataset.\")\n",
        "\n",
        "    print(\"\\n## Outcome model:\")\n",
        "    print(\" - Not specified\" if trial[\"outcome_model\"] is None\n",
        "          else f\" - Model: {trial['outcome_model']}\")\n",
        "\n",
        "trial_pp = trial_sequence(estimand=\"PP\")\n",
        "trial_itt = trial_sequence(estimand=\"ITT\")\n",
        "\n",
        "for dir_path in [os.path.join(os.getcwd(), \"trial_pp\"),\n",
        "                 os.path.join(os.getcwd(), \"trial_itt\")]:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "data_censored = pd.read_csv(\"data_censored.csv\")\n",
        "\n",
        "trial_pp = set_data(trial_pp, data_censored, \"id\", \"period\", \"treatment\", \"outcome\", \"eligible\")\n",
        "trial_itt = set_data(trial_itt, data_censored, \"id\", \"period\", \"treatment\", \"outcome\", \"eligible\")\n",
        "\n",
        "print(\"\\n\" + \"#\"*50)\n",
        "summarize_trial(trial_itt)\n",
        "print(\"#\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVA95vgm-m0B"
      },
      "source": [
        "# 3.1 Censoring due to treatment switching\n",
        "\n",
        "In the R code, the ```set_switch_weight_model()``` function is used to handle censoring due to treatment switching. This involves specifying numerator and denominator models to calculate the probability of receiving treatment in the current period, with separate models for patients based on their previous treatment status.\n",
        "\n",
        "To replicate this in Python, we can use logistic regression models from the ```statsmodels```library to estimate these probabilities. Here's how you can implement this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before estimating causal effects, we need to account for bias introduced by censoring and treatment switching. We do this using Inverse Probability of Censoring Weights (IPCW).\n",
        "\n",
        "### 3.1 Censoring Due to Treatment Switching\n",
        "Purpose:\n",
        "- Patients may switch treatments during the study period. If this switching is not random (e.g., sicker patients switching to treatment), it biases our estimates.\n",
        "- To adjust for this, we create models estimating the probability of sticking to the assigned treatment.\n",
        "\n",
        "2 models created: \n",
        "- Numerator Model: Estimates the probability of continuing treatment without adjusting for confounders.\n",
        "- Denominator Model: Estimates the probability of continuing treatment adjusting for confounders.\n",
        "- This weight ensures that patients who switch treatments donâ€™t bias our estimates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDaYb90k7BFA",
        "outputId": "444c9f6e-9626-4c0f-e96f-01f9ce7f4142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding trial_period to the dataset...\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:              treatment   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      722\n",
            "Method:                           MLE   Df Model:                            2\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.04216\n",
            "Time:                        21:55:52   Log-Likelihood:                -479.89\n",
            "converged:                       True   LL-Null:                       -501.01\n",
            "Covariance Type:            nonrobust   LLR p-value:                 6.713e-10\n",
            "================================================================================\n",
            "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "Intercept        1.7989      0.348      5.176      0.000       1.118       2.480\n",
            "age             -0.0383      0.008     -4.724      0.000      -0.054      -0.022\n",
            "trial_period    -0.0136      0.016     -0.847      0.397      -0.045       0.018\n",
            "================================================================================\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:              treatment   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      720\n",
            "Method:                           MLE   Df Model:                            4\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.04534\n",
            "Time:                        21:55:52   Log-Likelihood:                -478.29\n",
            "converged:                       True   LL-Null:                       -501.01\n",
            "Covariance Type:            nonrobust   LLR p-value:                 3.229e-09\n",
            "================================================================================\n",
            "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "Intercept        1.7348      0.372      4.667      0.000       1.006       2.463\n",
            "age             -0.0390      0.008     -4.754      0.000      -0.055      -0.023\n",
            "x1               0.2772      0.157      1.769      0.077      -0.030       0.584\n",
            "x3              -0.0263      0.155     -0.169      0.866      -0.330       0.278\n",
            "trial_period    -0.0141      0.016     -0.871      0.384      -0.046       0.018\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def fit_logistic_regression(formula, data):\n",
        "    \"\"\"Fit a logistic regression model.\"\"\"\n",
        "    model = sm.Logit.from_formula(formula, data)\n",
        "    result = model.fit(disp=False)\n",
        "    return result\n",
        "\n",
        "def set_switch_weight_model(trial, numerator_formula, denominator_formula, save_path=None):\n",
        "    \n",
        "    data = trial[\"data\"].copy()\n",
        "\n",
        "    numerator_model = fit_logistic_regression(numerator_formula, data)\n",
        "\n",
        "    denominator_model = fit_logistic_regression(denominator_formula, data)\n",
        "\n",
        "    trial[\"switch_weights\"] = {\n",
        "        \"numerator_model\": numerator_model,\n",
        "        \"denominator_model\": denominator_model\n",
        "    }\n",
        "\n",
        "    if save_path:\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        numerator_model.save(f\"{save_path}/numerator_model.pickle\")\n",
        "        denominator_model.save(f\"{save_path}/denominator_model.pickle\")\n",
        "\n",
        "    return trial\n",
        "\n",
        "if \"trial_period\" not in trial_pp[\"data\"].columns:\n",
        "    print(\"Adding trial_period to the dataset...\")\n",
        "    trial_pp[\"data\"][\"trial_period\"] = trial_pp[\"data\"][\"period\"]\n",
        "\n",
        "numerator_formula = 'treatment ~ age + trial_period'\n",
        "denominator_formula = 'treatment ~ age + x1 + x3 + trial_period'\n",
        "\n",
        "trial_pp = set_switch_weight_model(\n",
        "    trial_pp,\n",
        "    numerator_formula=numerator_formula,\n",
        "    denominator_formula=denominator_formula,\n",
        "    save_path='trial_pp/switch_models'\n",
        ")\n",
        "\n",
        "print(trial_pp[\"switch_weights\"][\"numerator_model\"].summary())\n",
        "print(trial_pp[\"switch_weights\"][\"denominator_model\"].summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHsDwHV8_eAl"
      },
      "source": [
        "# Step 3.2: Other Informative Censoring\n",
        "\n",
        "For other types of informative censoring, the R code uses the ```set_censor_weight_model()``` function to estimate inverse probability of censoring weights (IPCW). In Python, we can similarly fit logistic regression models to estimate the probability of censoring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Purpose:\n",
        "- Sometimes, patients drop out or are lost to follow-up due to factors related to their health (e.g., a patient in worse health is more likely to drop out).\n",
        "- If censoring is informative (not random), our estimates become biased.\n",
        "\n",
        "To do this we:\n",
        "- estimate the probability of staying in the study using the same stabilized weight approach as in treatment switching.\n",
        "- These weights adjust for non-random censoring, making the remaining data more representative of the original population."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBrx9ZU9_7Oq",
        "outputId": "b801545f-1261-4335-db1a-33bd68cf509e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding trial_period to the dataset...\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:           not_censored   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      722\n",
            "Method:                           MLE   Df Model:                            2\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                  0.1474\n",
            "Time:                        21:55:52   Log-Likelihood:                -172.32\n",
            "converged:                       True   LL-Null:                       -202.11\n",
            "Covariance Type:            nonrobust   LLR p-value:                 1.163e-13\n",
            "================================================================================\n",
            "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "Intercept        1.3754      0.191      7.218      0.000       1.002       1.749\n",
            "x2              -0.4666      0.149     -3.125      0.002      -0.759      -0.174\n",
            "trial_period     0.2413      0.045      5.363      0.000       0.153       0.329\n",
            "================================================================================\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:           not_censored   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      721\n",
            "Method:                           MLE   Df Model:                            3\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                  0.1610\n",
            "Time:                        21:55:52   Log-Likelihood:                -169.56\n",
            "converged:                       True   LL-Null:                       -202.11\n",
            "Covariance Type:            nonrobust   LLR p-value:                 4.796e-14\n",
            "================================================================================\n",
            "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "Intercept        1.1290      0.213      5.301      0.000       0.712       1.546\n",
            "x2              -0.5113      0.151     -3.389      0.001      -0.807      -0.216\n",
            "x1               0.7257      0.320      2.267      0.023       0.098       1.353\n",
            "trial_period     0.2420      0.045      5.350      0.000       0.153       0.331\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "def set_censor_weight_model(trial, censor_event_col, numerator_formula, denominator_formula, save_path=None):\n",
        "    \n",
        "    data = trial[\"data\"].copy()\n",
        "\n",
        "    if \"trial_period\" not in data.columns:\n",
        "        print(\"Adding trial_period to the dataset...\")\n",
        "        data[\"trial_period\"] = data[\"period\"] \n",
        "\n",
        "    data['not_censored'] = 1 - data[censor_event_col]\n",
        "\n",
        "    numerator_model = fit_logistic_regression(numerator_formula, data)\n",
        "\n",
        "    denominator_model = fit_logistic_regression(denominator_formula, data)\n",
        "\n",
        "    trial[\"censor_weights\"] = {\n",
        "        \"numerator_model\": numerator_model,\n",
        "        \"denominator_model\": denominator_model\n",
        "    }\n",
        "\n",
        "    if save_path:\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        numerator_model.save(os.path.join(save_path, \"numerator_model.pickle\"))\n",
        "        denominator_model.save(os.path.join(save_path, \"denominator_model.pickle\"))  \n",
        "\n",
        "    return trial\n",
        "\n",
        "numerator_formula = 'not_censored ~ x2 + trial_period'\n",
        "denominator_formula = 'not_censored ~ x2 + x1 + trial_period'\n",
        "\n",
        "trial_pp = set_censor_weight_model(\n",
        "    trial_pp,\n",
        "    censor_event_col='censored',\n",
        "    numerator_formula=numerator_formula,\n",
        "    denominator_formula=denominator_formula,\n",
        "    save_path='trial_pp/censor_models'\n",
        ")\n",
        "\n",
        "trial_itt = set_censor_weight_model(\n",
        "    trial_itt,\n",
        "    censor_event_col='censored',\n",
        "    numerator_formula=numerator_formula,\n",
        "    denominator_formula=denominator_formula,\n",
        "    save_path='trial_itt/censor_models'\n",
        ")\n",
        "\n",
        "print(trial_itt[\"censor_weights\"][\"numerator_model\"].summary())\n",
        "print(trial_itt[\"censor_weights\"][\"denominator_model\"].summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPw94_onAhpS"
      },
      "source": [
        "# Step 4: Calculate Weights\n",
        "\n",
        "In the R code, the ```calculate_weights()``` function is used to fit the models specified earlier and compute the inverse probability weights. To replicate this functionality in Python:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have created models for treatment switching and censoring, we calculate the final weights to apply in the outcome model.\n",
        "\n",
        "The function calculate_weights() takes:\n",
        "- Treatment switching weights (Step 3.1)\n",
        "- Censoring weights (Step 3.2)\n",
        "- Combines them into final IP weights to be applied in Step 8.\n",
        "These weights adjust for both:\n",
        "- Non-random treatment switching.\n",
        "= Informative censoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ld40cliBUbF",
        "outputId": "10056c11-fa08-4e55-c5ea-392a8a537041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Intention-to-Treat (ITT) Trial Weight Models\n",
            "##################################################\n",
            "\n",
            "Weight Models for Treatment Switching\n",
            "-------------------------------------\n",
            "\n",
            "Numerator Model Summary:\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:              treatment   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      723\n",
            "Method:                           MLE   Df Model:                            1\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.04144\n",
            "Time:                        21:55:52   Log-Likelihood:                -480.24\n",
            "converged:                       True   LL-Null:                       -501.01\n",
            "Covariance Type:            nonrobust   LLR p-value:                 1.163e-10\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      1.8867      0.333      5.671      0.000       1.235       2.539\n",
            "age           -0.0421      0.007     -6.213      0.000      -0.055      -0.029\n",
            "==============================================================================\n",
            "\n",
            "Denominator Model Summary:\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:              treatment   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      721\n",
            "Method:                           MLE   Df Model:                            3\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.04459\n",
            "Time:                        21:55:52   Log-Likelihood:                -478.67\n",
            "converged:                       True   LL-Null:                       -501.01\n",
            "Covariance Type:            nonrobust   LLR p-value:                 1.084e-09\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      1.8308      0.356      5.145      0.000       1.133       2.528\n",
            "age           -0.0429      0.007     -6.261      0.000      -0.056      -0.029\n",
            "x1             0.2744      0.157      1.752      0.080      -0.033       0.581\n",
            "x3            -0.0321      0.155     -0.207      0.836      -0.336       0.272\n",
            "==============================================================================\n",
            "\n",
            "Weight Models for Informative Censoring\n",
            "---------------------------------------\n",
            "\n",
            "Numerator Model Summary:\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:           not_censored   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      723\n",
            "Method:                           MLE   Df Model:                            1\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.02676\n",
            "Time:                        21:55:52   Log-Likelihood:                -196.70\n",
            "converged:                       True   LL-Null:                       -202.11\n",
            "Covariance Type:            nonrobust   LLR p-value:                  0.001007\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      2.4481      0.141     17.415      0.000       2.173       2.724\n",
            "x2            -0.4486      0.137     -3.278      0.001      -0.717      -0.180\n",
            "==============================================================================\n",
            "\n",
            "Denominator Model Summary:\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:           not_censored   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      722\n",
            "Method:                           MLE   Df Model:                            2\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.04069\n",
            "Time:                        21:55:52   Log-Likelihood:                -193.88\n",
            "converged:                       True   LL-Null:                       -202.11\n",
            "Covariance Type:            nonrobust   LLR p-value:                 0.0002679\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      2.2059      0.165     13.339      0.000       1.882       2.530\n",
            "x2            -0.4706      0.137     -3.423      0.001      -0.740      -0.201\n",
            "x1             0.7019      0.307      2.285      0.022       0.100       1.304\n",
            "==============================================================================\n",
            "\n",
            "##################################################\n",
            "Per-Protocol (PP) Trial Weight Models\n",
            "##################################################\n",
            "\n",
            "Weight Models for Treatment Switching\n",
            "-------------------------------------\n",
            "\n",
            "Numerator Model Summary:\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:              treatment   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      722\n",
            "Method:                           MLE   Df Model:                            2\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.04216\n",
            "Time:                        21:55:52   Log-Likelihood:                -479.89\n",
            "converged:                       True   LL-Null:                       -501.01\n",
            "Covariance Type:            nonrobust   LLR p-value:                 6.713e-10\n",
            "================================================================================\n",
            "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "Intercept        1.7989      0.348      5.176      0.000       1.118       2.480\n",
            "age             -0.0383      0.008     -4.724      0.000      -0.054      -0.022\n",
            "trial_period    -0.0136      0.016     -0.847      0.397      -0.045       0.018\n",
            "================================================================================\n",
            "\n",
            "Denominator Model Summary:\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:              treatment   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      720\n",
            "Method:                           MLE   Df Model:                            4\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.04534\n",
            "Time:                        21:55:52   Log-Likelihood:                -478.29\n",
            "converged:                       True   LL-Null:                       -501.01\n",
            "Covariance Type:            nonrobust   LLR p-value:                 3.229e-09\n",
            "================================================================================\n",
            "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "Intercept        1.7348      0.372      4.667      0.000       1.006       2.463\n",
            "age             -0.0390      0.008     -4.754      0.000      -0.055      -0.023\n",
            "x1               0.2772      0.157      1.769      0.077      -0.030       0.584\n",
            "x3              -0.0263      0.155     -0.169      0.866      -0.330       0.278\n",
            "trial_period    -0.0141      0.016     -0.871      0.384      -0.046       0.018\n",
            "================================================================================\n",
            "\n",
            "Weight Models for Informative Censoring\n",
            "---------------------------------------\n",
            "\n",
            "Numerator Model Summary:\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:           not_censored   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      722\n",
            "Method:                           MLE   Df Model:                            2\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                  0.1474\n",
            "Time:                        21:55:52   Log-Likelihood:                -172.32\n",
            "converged:                       True   LL-Null:                       -202.11\n",
            "Covariance Type:            nonrobust   LLR p-value:                 1.163e-13\n",
            "================================================================================\n",
            "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "Intercept        1.3754      0.191      7.218      0.000       1.002       1.749\n",
            "x2              -0.4666      0.149     -3.125      0.002      -0.759      -0.174\n",
            "trial_period     0.2413      0.045      5.363      0.000       0.153       0.329\n",
            "================================================================================\n",
            "\n",
            "Denominator Model Summary:\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:           not_censored   No. Observations:                  725\n",
            "Model:                          Logit   Df Residuals:                      721\n",
            "Method:                           MLE   Df Model:                            3\n",
            "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                  0.1610\n",
            "Time:                        21:55:52   Log-Likelihood:                -169.56\n",
            "converged:                       True   LL-Null:                       -202.11\n",
            "Covariance Type:            nonrobust   LLR p-value:                 4.796e-14\n",
            "================================================================================\n",
            "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "Intercept        1.1290      0.213      5.301      0.000       0.712       1.546\n",
            "x2              -0.5113      0.151     -3.389      0.001      -0.807      -0.216\n",
            "x1               0.7257      0.320      2.267      0.023       0.098       1.353\n",
            "trial_period     0.2420      0.045      5.350      0.000       0.153       0.331\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def fit_logistic_regression(formula, data):\n",
        "    \"\"\"Fit a logistic regression model.\"\"\"\n",
        "    model = sm.Logit.from_formula(formula, data)\n",
        "    result = model.fit(disp=False)\n",
        "    return result\n",
        "\n",
        "def check_multicollinearity(data, predictors):\n",
        "    \"\"\"Compute VIF for each predictor.\"\"\"\n",
        "    X = data[predictors].dropna() \n",
        "    X = sm.add_constant(X) \n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = X.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "def set_switch_weight_model(trial, numerator_formula, denominator_formula, save_path=None):\n",
        "\n",
        "    data = trial[\"data\"].copy()\n",
        "\n",
        "    if \"trial_period\" not in trial_pp[\"data\"].columns or trial_pp[\"data\"][\"trial_period\"].isna().all():\n",
        "        trial_pp[\"data\"][\"trial_period\"] = trial_pp[\"data\"].groupby(\"id\").cumcount()\n",
        "\n",
        "    if \"trial_period\" not in trial_itt[\"data\"].columns or trial_itt[\"data\"][\"trial_period\"].isna().all():\n",
        "        trial_itt[\"data\"][\"trial_period\"] = trial_itt[\"data\"].groupby(\"id\").cumcount()\n",
        "\n",
        "    numerator_model = fit_logistic_regression(numerator_formula, data)\n",
        "\n",
        "    denominator_model = fit_logistic_regression(denominator_formula, data)\n",
        "\n",
        "    trial[\"switch_weights\"] = {\n",
        "        \"numerator_model\": numerator_model,\n",
        "        \"denominator_model\": denominator_model\n",
        "    }\n",
        "\n",
        "    if save_path:\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        numerator_model.save(os.path.join(save_path, \"numerator_model.pickle\"))\n",
        "        denominator_model.save(os.path.join(save_path, \"denominator_model.pickle\"))\n",
        "\n",
        "    return trial\n",
        "\n",
        "\n",
        "def set_censor_weight_model(trial, censor_event_col, numerator_formula, denominator_formula, save_path=None):\n",
        "\n",
        "    data = trial[\"data\"].copy()\n",
        "\n",
        "    if \"trial_period\" not in trial_pp[\"data\"].columns or trial_pp[\"data\"][\"trial_period\"].isna().all():\n",
        "        trial_pp[\"data\"][\"trial_period\"] = trial_pp[\"data\"].groupby(\"id\").cumcount()\n",
        "\n",
        "    if \"trial_period\" not in trial_itt[\"data\"].columns or trial_itt[\"data\"][\"trial_period\"].isna().all():\n",
        "        trial_itt[\"data\"][\"trial_period\"] = trial_itt[\"data\"].groupby(\"id\").cumcount()\n",
        "\n",
        "    data['not_censored'] = 1 - data[censor_event_col]\n",
        "\n",
        "    numerator_model = fit_logistic_regression(numerator_formula, data)\n",
        "\n",
        "    denominator_model = fit_logistic_regression(denominator_formula, data)\n",
        "\n",
        "    data['p_numerator'] = numerator_model.predict(data)\n",
        "    data['p_denominator'] = denominator_model.predict(data)\n",
        "\n",
        "    data['weight'] = data['p_numerator'] / data['p_denominator']\n",
        "\n",
        "    trial[\"data\"] = data\n",
        "    trial[\"censor_weights\"] = {\n",
        "        \"numerator_model\": numerator_model,\n",
        "        \"denominator_model\": denominator_model\n",
        "    }\n",
        "\n",
        "   \n",
        "    if save_path:\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        numerator_model.save(os.path.join(save_path, \"numerator_model.pickle\"))\n",
        "        denominator_model.save(os.path.join(save_path, \"denominator_model.pickle\"))\n",
        "\n",
        "    return trial\n",
        "\n",
        "\n",
        "if \"trial_period\" not in trial_pp[\"data\"].columns or trial_pp[\"data\"][\"trial_period\"].isna().all():\n",
        "        trial_pp[\"data\"][\"trial_period\"] = trial_pp[\"data\"].groupby(\"id\").cumcount()\n",
        "\n",
        "if \"trial_period\" not in trial_itt[\"data\"].columns or trial_itt[\"data\"][\"trial_period\"].isna().all():\n",
        "        trial_itt[\"data\"][\"trial_period\"] = trial_itt[\"data\"].groupby(\"id\").cumcount()\n",
        "\n",
        "\n",
        "switch_numerator_formula_itt = 'treatment ~ age'  \n",
        "switch_denominator_formula_itt = 'treatment ~ age + x1 + x3'\n",
        "\n",
        "censor_numerator_formula_itt = 'not_censored ~ x2'\n",
        "censor_denominator_formula_itt = 'not_censored ~ x2 + x1'\n",
        "\n",
        "switch_numerator_formula_pp = 'treatment ~ age + trial_period'\n",
        "switch_denominator_formula_pp = 'treatment ~ age + x1 + x3 + trial_period'\n",
        "\n",
        "censor_numerator_formula_pp = 'not_censored ~ x2 + trial_period'\n",
        "censor_denominator_formula_pp = 'not_censored ~ x2 + x1 + trial_period'\n",
        "\n",
        "\n",
        "trial_pp = set_switch_weight_model(\n",
        "    trial_pp,\n",
        "    numerator_formula=switch_numerator_formula_pp,\n",
        "    denominator_formula=switch_denominator_formula_pp,\n",
        "    save_path='trial_pp/switch_models'\n",
        ")\n",
        "trial_pp = set_censor_weight_model(\n",
        "    trial_pp,\n",
        "    censor_event_col='censored',\n",
        "    numerator_formula=censor_numerator_formula_pp,\n",
        "    denominator_formula=censor_denominator_formula_pp,\n",
        "    save_path='trial_pp/censor_models'\n",
        ")\n",
        "\n",
        "trial_itt = set_switch_weight_model(\n",
        "    trial_itt,\n",
        "    numerator_formula=switch_numerator_formula_itt,\n",
        "    denominator_formula=switch_denominator_formula_itt,\n",
        "    save_path='trial_itt/switch_models'\n",
        ")\n",
        "trial_itt = set_censor_weight_model(\n",
        "    trial_itt,\n",
        "    censor_event_col='censored',\n",
        "    numerator_formula=censor_numerator_formula_itt,\n",
        "    denominator_formula=censor_denominator_formula_itt,\n",
        "    save_path='trial_itt/censor_models'\n",
        ")\n",
        "\n",
        "def show_weight_models(trial):\n",
        "    \"\"\"\n",
        "    Display summaries of the weight models for treatment switching and informative censoring.\n",
        "    \"\"\"\n",
        "    if \"switch_weights\" in trial:\n",
        "        print(\"Weight Models for Treatment Switching\")\n",
        "        print(\"-------------------------------------\")\n",
        "        switch_weights = trial[\"switch_weights\"]\n",
        "        if \"numerator_model\" in switch_weights:\n",
        "            print(\"\\nNumerator Model Summary:\")\n",
        "            print(switch_weights[\"numerator_model\"].summary())\n",
        "        if \"denominator_model\" in switch_weights:\n",
        "            print(\"\\nDenominator Model Summary:\")\n",
        "            print(switch_weights[\"denominator_model\"].summary())\n",
        "\n",
        "    if \"censor_weights\" in trial:\n",
        "        print(\"\\nWeight Models for Informative Censoring\")\n",
        "        print(\"---------------------------------------\")\n",
        "        censor_weights = trial[\"censor_weights\"]\n",
        "        if \"numerator_model\" in censor_weights:\n",
        "            print(\"\\nNumerator Model Summary:\")\n",
        "            print(censor_weights[\"numerator_model\"].summary())\n",
        "        if \"denominator_model\" in censor_weights:\n",
        "            print(\"\\nDenominator Model Summary:\")\n",
        "            print(censor_weights[\"denominator_model\"].summary())\n",
        "\n",
        "print(\"\\n\" + \"#\"*50)\n",
        "print(\"Intention-to-Treat (ITT) Trial Weight Models\")\n",
        "print(\"#\"*50 + \"\\n\")\n",
        "show_weight_models(trial_itt)\n",
        "\n",
        "print(\"\\n\" + \"#\"*50)\n",
        "print(\"Per-Protocol (PP) Trial Weight Models\")\n",
        "print(\"#\"*50 + \"\\n\")\n",
        "show_weight_models(trial_pp)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuHgQOVzCfgU"
      },
      "source": [
        "# Step 5: Set Expansion Options\n",
        "\n",
        "In this step, we define how the trial data should be expanded by specifying parameters such as the output method and chunk size. This setup prepares the trial object for the expansion process.\n",
        "\n",
        "## ```set_expansion_options``` Function:\n",
        "Adds an ```expansion_options``` dictionary to the trial object, containing the output function and chunk size.\n",
        "\n",
        "## ```save_to_csv``` Function:\n",
        "Generates a function that saves each data chunk to a CSV file in the specified directory. This function is assigned to the ```output_func``` parameter in ```set_expansion_options```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Outcome Model Structure:\n",
        "Outcome = Treatment + Confounders + Weights Applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PK2Rc14DDcG"
      },
      "outputs": [],
      "source": [
        "def set_outcome_model(trial, outcome_col=\"outcome\", adjustment_terms=None):\n",
        "    formula = f\"{outcome_col} ~ treatment\"\n",
        "\n",
        "    if adjustment_terms:\n",
        "        formula += \" + \" + \" + \".join(adjustment_terms)\n",
        "\n",
        "    trial[\"outcome_model\"] = formula\n",
        "\n",
        "    print(f\"\\nOutcome model set for {trial['estimand']} trial:\")\n",
        "    print(f\"Formula: {formula}\")\n",
        "\n",
        "    return trial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Outcome model set for PP trial:\n",
            "Formula: outcome ~ treatment\n",
            "\n",
            "Outcome model set for ITT trial:\n",
            "Formula: outcome ~ treatment + x2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "trial_pp = set_outcome_model(trial_pp)\n",
        "\n",
        "trial_itt = set_outcome_model(trial_itt, adjustment_terms=[\"x2\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b55fBKHyCjBW"
      },
      "source": [
        "# Step 6: Expand Trials\n",
        "\n",
        "With the expansion options set, this step involves processing the trial data in chunks as specified, applying the output function to each chunk to generate the expanded dataset.\n",
        "\n",
        "## ```expand_trials``` Function:\n",
        "Retrieves the data and expansion options from the trial object, divides the data into chunks based on the specified chunk size, and applies the output function to each chunk. The ```output_func``` is called with the data chunk and its corresponding chunk index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The dataset is expanded so that each row represents a patient at a given time point.\n",
        "- This ensures the model can estimate longitudinal effects of treatment over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hl_3-BpA2qP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## Sequence of Trials Data:\n",
            "## --------------------------\n",
            "- Chunk size: 500\n",
            "- Censor at switch: TRUE\n",
            "- First period: 0 | Last period: Inf\n",
            "\n",
            "## A TE Datastore Datatable object\n",
            "N: 44500 observations\n",
            "\n",
            "  id  trial_period  followup_time  outcome   weight  treatment       x2  age  assigned_treatment\n",
            "1.0             0              0      0.0 0.834219        1.0 1.146148 36.0                   1\n",
            "1.0             1              1      0.0 0.849393        1.0 1.146148 36.0                   1\n",
            "1.0             2              2      0.0 0.862840        1.0 1.146148 36.0                   1\n",
            "1.0             3              3      0.0 0.874501        1.0 1.146148 36.0                   1\n",
            "1.0             4              4      0.0 0.884416        1.0 1.146148 36.0                   1\n",
            "...\n",
            "  id  trial_period  followup_time  outcome   weight  treatment        x2  age  assigned_treatment\n",
            "99.0           495            495      0.0 1.081514        1.0 -0.346378 65.0                   1\n",
            "99.0           496            496      0.0 1.081996        1.0 -0.346378 65.0                   1\n",
            "99.0           497            497      0.0 1.082478        1.0 -0.346378 65.0                   1\n",
            "99.0           498            498      0.0 1.082960        1.0 -0.346378 65.0                   1\n",
            "99.0           499            499      0.0 1.083442        1.0 -0.346378 65.0                   1\n",
            "\n",
            "## Sequence of Trials Data:\n",
            "## --------------------------\n",
            "- Chunk size: 500\n",
            "- Censor at switch: TRUE\n",
            "- First period: 0 | Last period: Inf\n",
            "\n",
            "## A TE Datastore Datatable object\n",
            "N: 44500 observations\n",
            "\n",
            "  id  trial_period  followup_time  outcome   weight  treatment       x2  age  assigned_treatment\n",
            "1.0             0              0      0.0 0.888682        1.0 1.146148 36.0                   1\n",
            "1.0             1              1      0.0 0.888682        1.0 1.146148 36.0                   1\n",
            "1.0             2              2      0.0 0.888682        1.0 1.146148 36.0                   1\n",
            "1.0             3              3      0.0 0.888682        1.0 1.146148 36.0                   1\n",
            "1.0             4              4      0.0 0.888682        1.0 1.146148 36.0                   1\n",
            "...\n",
            "  id  trial_period  followup_time  outcome   weight  treatment        x2  age  assigned_treatment\n",
            "99.0           495            495      0.0 0.890294        1.0 -0.346378 65.0                   1\n",
            "99.0           496            496      0.0 0.890294        1.0 -0.346378 65.0                   1\n",
            "99.0           497            497      0.0 0.890294        1.0 -0.346378 65.0                   1\n",
            "99.0           498            498      0.0 0.890294        1.0 -0.346378 65.0                   1\n",
            "99.0           499            499      0.0 0.890294        1.0 -0.346378 65.0                   1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def compute_expanded_weights(expanded_data, switch_weights, censor_weights):\n",
        "    \"\"\"\n",
        "    Compute the weight dynamically using switch and censoring weights\n",
        "    for the expanded dataset in batch mode.\n",
        "    \"\"\"\n",
        "    treatment_prob = (\n",
        "        switch_weights[\"numerator_model\"].predict(expanded_data) /\n",
        "        switch_weights[\"denominator_model\"].predict(expanded_data)\n",
        "    ).astype(float)\n",
        "\n",
        "    censor_prob = (\n",
        "        censor_weights[\"numerator_model\"].predict(expanded_data) /\n",
        "        censor_weights[\"denominator_model\"].predict(expanded_data)\n",
        "    ).astype(float)\n",
        "\n",
        "    return treatment_prob * censor_prob \n",
        "\n",
        "\n",
        "def expand_trials(trial, chunk_size=500):\n",
        "    \"\"\"\n",
        "    Expand the dataset to include a sequence of target trials.\n",
        "    Now computes weights efficiently using batch processing.\n",
        "    \"\"\"\n",
        "    data = trial[\"data\"].copy()\n",
        "\n",
        "    required_cols = [\"id\", \"treatment\", \"outcome\", \"x2\", \"age\", \"censored\"]\n",
        "    for col in required_cols:\n",
        "        if col not in data.columns:\n",
        "            raise ValueError(f\"Column '{col}' is missing from the dataset.\")\n",
        "        \n",
        "    if \"switch_weights\" not in trial or \"censor_weights\" not in trial:\n",
        "        raise ValueError(\"Weight models are missing. Run `set_switch_weight_model` and `set_censor_weight_model` first.\")\n",
        "\n",
        "\n",
        "    expanded_rows = []\n",
        "\n",
        "    for _, patient_data in data.groupby(\"id\"):\n",
        "        patient_id = patient_data[\"id\"].iloc[0]\n",
        "        assigned_treatment = patient_data[\"treatment\"].iloc[0]  \n",
        "        \n",
        "        expanded_patient_data = pd.DataFrame([patient_data.iloc[0]] * chunk_size)  \n",
        "        expanded_patient_data[\"trial_period\"] = range(chunk_size)\n",
        "        expanded_patient_data[\"followup_time\"] = range(chunk_size)\n",
        "        expanded_patient_data[\"assigned_treatment\"] = assigned_treatment\n",
        "\n",
        "        expanded_rows.append(expanded_patient_data)\n",
        "\n",
        "    expanded_data = pd.concat(expanded_rows, ignore_index=True)\n",
        "\n",
        "    expanded_data[\"weight\"] = compute_expanded_weights(\n",
        "        expanded_data, \n",
        "        trial[\"switch_weights\"], \n",
        "        trial[\"censor_weights\"]\n",
        "    )\n",
        "\n",
        "    trial[\"expanded_data\"] = expanded_data\n",
        "\n",
        "    return trial\n",
        "\n",
        "\n",
        "def display_expanded_trial(trial):\n",
        "    \"\"\"\n",
        "    Display the expanded sequence of trials data in R-style output format.\n",
        "    \"\"\"\n",
        "    data = trial[\"expanded_data\"].copy()\n",
        "\n",
        "    print(\"\\n## Sequence of Trials Data:\")\n",
        "    print(\"## --------------------------\")\n",
        "    print(f\"- Chunk size: 500\")\n",
        "    print(f\"- Censor at switch: TRUE\")\n",
        "    print(f\"- First period: 0 | Last period: Inf\")\n",
        "    print(\"\\n## A TE Datastore Datatable object\")\n",
        "    print(f\"N: {len(data)} observations\")\n",
        "\n",
        "\n",
        "    print(\"\\n\", data[[\"id\", \"trial_period\", \"followup_time\", \"outcome\", \"weight\", \n",
        "                     \"treatment\", \"x2\", \"age\", \"assigned_treatment\"]].head(5).to_string(index=False))\n",
        "    print(\"...\")\n",
        "    print(data[[\"id\", \"trial_period\", \"followup_time\", \"outcome\", \"weight\", \n",
        "                \"treatment\", \"x2\", \"age\", \"assigned_treatment\"]].tail(5).to_string(index=False))\n",
        "\n",
        "\n",
        "trial_pp = expand_trials(trial_pp, chunk_size=500)\n",
        "trial_itt = expand_trials(trial_itt, chunk_size=500)\n",
        "\n",
        "display_expanded_trial(trial_pp)\n",
        "\n",
        "\n",
        "display_expanded_trial(trial_itt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPhhWmb3FWCL"
      },
      "source": [
        "# Step 7: Load or Sample from Expanded Data\n",
        "\n",
        "After expanding the trial data, we prepare it for fitting the outcome model. If the dataset is manageable in size, we can load it directly into memory. For larger datasets, sampling may be necessary to ensure efficient processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8rAcgOBGVlF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## Sampled Per-Protocol (PP) Data:\n",
            "     id  period  treatment   x1        x2   x3        x4   age     age_s  \\\n",
            "0  74.0     0.0        0.0  0.0 -1.550428  0.0 -1.872546  42.0  0.583333   \n",
            "1  14.0     0.0        0.0  0.0  0.595125  1.0 -0.427362  39.0  0.333333   \n",
            "2  11.0     0.0        0.0  0.0  0.926011  1.0  0.682986  23.0 -1.000000   \n",
            "3  54.0     0.0        0.0  1.0  1.292413  1.0 -1.016741  52.0  1.416667   \n",
            "4  73.0     0.0        0.0  0.0 -0.399040  1.0  0.959075  33.0 -0.166667   \n",
            "\n",
            "   outcome  censored  eligible  trial_period  not_censored  p_numerator  \\\n",
            "0      0.0       0.0       1.0           110           1.0     0.890779   \n",
            "1      0.0       0.0       1.0           457           1.0     0.749831   \n",
            "2      0.0       1.0       1.0            77           0.0     0.719773   \n",
            "3      0.0       0.0       1.0           387           1.0     0.684038   \n",
            "4      0.0       0.0       1.0            36           1.0     0.826575   \n",
            "\n",
            "   p_denominator    weight  followup_time  assigned_treatment  \n",
            "0       0.872325  1.120184            110                   0  \n",
            "1       0.695242  1.377091            457                   0  \n",
            "2       0.658265  1.080323             77                   0  \n",
            "3       0.767441  1.021476            387                   0  \n",
            "4       0.791340  1.067396             36                   0  \n",
            "\n",
            "## Sampled Intention-to-Treat (ITT) Data:\n",
            "     id  period  treatment   x1        x2   x3        x4   age     age_s  \\\n",
            "0  74.0     0.0        0.0  0.0 -1.550428  0.0 -1.872546  42.0  0.583333   \n",
            "1  14.0     0.0        0.0  0.0  0.595125  1.0 -0.427362  39.0  0.333333   \n",
            "2  11.0     0.0        0.0  0.0  0.926011  1.0  0.682986  23.0 -1.000000   \n",
            "3  54.0     0.0        0.0  1.0  1.292413  1.0 -1.016741  52.0  1.416667   \n",
            "4  73.0     0.0        0.0  0.0 -0.399040  1.0  0.959075  33.0 -0.166667   \n",
            "\n",
            "   outcome  censored  eligible  trial_period  not_censored  p_numerator  \\\n",
            "0      0.0       0.0       1.0           110           1.0     0.958659   \n",
            "1      0.0       0.0       1.0           457           1.0     0.898538   \n",
            "2      0.0       1.0       1.0            77           0.0     0.884181   \n",
            "3      0.0       0.0       1.0           387           1.0     0.866256   \n",
            "4      0.0       0.0       1.0            36           1.0     0.932587   \n",
            "\n",
            "   p_denominator    weight  followup_time  assigned_treatment  \n",
            "0       0.949577  1.055025            110                   0  \n",
            "1       0.872782  1.087619            457                   0  \n",
            "2       0.854464  1.068257             77                   0  \n",
            "3       0.908840  0.880460            387                   0  \n",
            "4       0.916344  1.065001             36                   0  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/hd/c_2b3t_14szgdqrwty6fx4p80000gn/T/ipykernel_92058/1119312220.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sampled_data = expanded_data.groupby(\"treatment\", group_keys=False).apply(\n",
            "/var/folders/hd/c_2b3t_14szgdqrwty6fx4p80000gn/T/ipykernel_92058/1119312220.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sampled_data = expanded_data.groupby(\"treatment\", group_keys=False).apply(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def sample_expanded_data(trial, sample_size=1000, random_state=42):\n",
        "   \n",
        "    expanded_data = trial[\"expanded_data\"].copy()\n",
        "    if len(expanded_data) < sample_size:\n",
        "        print(f\"Warning: Sample size ({sample_size}) is larger than available data ({len(expanded_data)}). Using full dataset.\")\n",
        "        sampled_data = expanded_data\n",
        "    else:\n",
        "    \n",
        "        sampled_data = expanded_data.groupby(\"treatment\", group_keys=False).apply(\n",
        "            lambda x: x.sample(n=int(sample_size / expanded_data[\"treatment\"].nunique()), random_state=random_state)\n",
        "        )\n",
        "\n",
        "    return sampled_data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "sampled_pp = sample_expanded_data(trial_pp, sample_size=1000)\n",
        "sampled_itt = sample_expanded_data(trial_itt, sample_size=1000)\n",
        "\n",
        "\n",
        "print(\"\\n## Sampled Per-Protocol (PP) Data:\")\n",
        "print(sampled_pp.head())\n",
        "\n",
        "print(\"\\n## Sampled Intention-to-Treat (ITT) Data:\")\n",
        "print(sampled_itt.head())\n",
        "\n",
        "\n",
        "trial_pp[\"sampled_data\"] = sampled_pp\n",
        "trial_itt[\"sampled_data\"] = sampled_itt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD2YVfB5Gmr4"
      },
      "source": [
        "# Step 8: Fit Marginal Structural Model\n",
        "\n",
        "To fit an MSM, we utilize inverse probability weighting (IPW). The ```zEpid``` library provides tools to calculate these weights and fit the MSM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1 Model Specification:\n",
        "Outcome = Treatment + Confounders + FollowupTime\n",
        "- Inverse probability weights (IPW) from Step 4 are applied.\n",
        "- Time-dependent confounders are adjusted.\n",
        "\n",
        "### 8.2 Multicollinearity Issues:\n",
        "- High correlation between followup_time and trial_period caused instability in the model.\n",
        "- Solution: Standardizing followup_time (followup_time_std) reduced correlation and VIF issues.\n",
        "- Result: Model now runs, but follow-up time does not impact survival predictions, leading to a flat survival curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "Hkl4zdd8GJYe",
        "outputId": "30c8c192-0253-44c6-83e8-110a88681995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ” Checking variation in follow-up time:\n",
            "followup_time_std\n",
            "-1.728571    89\n",
            " 0.550787    89\n",
            " 0.640853    89\n",
            " 0.633925    89\n",
            " 0.626997    89\n",
            " 0.620068    89\n",
            " 0.613140    89\n",
            " 0.606212    89\n",
            " 0.599284    89\n",
            " 0.592356    89\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ” Checking Correlation Between Follow-Up Time and Trial Period:\n",
            "                   followup_time_std\n",
            "followup_time_std                1.0\n",
            "\n",
            "ðŸ” Updated VIF after standardizing follow-up time:\n",
            "             Feature       VIF\n",
            "0              const  1.000914\n",
            "1                 x2  1.000000\n",
            "2  followup_time_std  1.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sakurakano/DataAnalytics/.venv/lib/python3.9/site-packages/statsmodels/base/l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 2 out of 4 parameters\n",
            "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
            "  warnings.warn(message, ConvergenceWarning)\n",
            "/Users/sakurakano/DataAnalytics/.venv/lib/python3.9/site-packages/statsmodels/base/l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
            "  warnings.warn(msg, ConvergenceWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ” Checking variation in follow-up time:\n",
            "followup_time_std\n",
            "-1.728571    89\n",
            " 0.550787    89\n",
            " 0.640853    89\n",
            " 0.633925    89\n",
            " 0.626997    89\n",
            " 0.620068    89\n",
            " 0.613140    89\n",
            " 0.606212    89\n",
            " 0.599284    89\n",
            " 0.592356    89\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ” Checking Correlation Between Follow-Up Time and Trial Period:\n",
            "                   followup_time_std\n",
            "followup_time_std                1.0\n",
            "\n",
            "ðŸ” Updated VIF after standardizing follow-up time:\n",
            "             Feature       VIF\n",
            "0              const  1.000914\n",
            "1                 x2  1.000000\n",
            "2  followup_time_std  1.000000\n",
            "\n",
            "##################################################\n",
            "Intention-to-Treat (ITT) Trial Outcome Model\n",
            "##################################################\n",
            "\n",
            "\n",
            "## Outcome Model Specification\n",
            "Formula: outcome ~ assigned_treatment + x2 + followup_time_std\n",
            "Treatment Variable: assigned_treatment\n",
            "Adjustment Variables: x2\n",
            "Model Fitter: Weighted Logistic Regression\n",
            "\n",
            "## Regression Coefficients & Interpretation\n",
            "              Term      Estimate\n",
            "         Intercept -1.352554e+01\n",
            "assigned_treatment  1.022324e+01\n",
            "                x2  5.721033e-01\n",
            " followup_time_std -5.890204e-24\n",
            "\n",
            "## Model Summary Statistics\n",
            "Number of Observations: 44500\n",
            "\n",
            "## Sample Data\n",
            " id  trial_period  followup_time  outcome   weight  assigned_treatment\n",
            "1.0             0              0      0.0 0.888682                   1\n",
            "1.0             1              1      0.0 0.888682                   1\n",
            "1.0             2              2      0.0 0.888682                   1\n",
            "1.0             3              3      0.0 0.888682                   1\n",
            "1.0             4              4      0.0 0.888682                   1\n",
            "\n",
            "##################################################\n",
            "Per-Protocol (PP) Trial Outcome Model\n",
            "##################################################\n",
            "\n",
            "\n",
            "## Outcome Model Specification\n",
            "Formula: outcome ~ assigned_treatment + x2 + followup_time_std\n",
            "Treatment Variable: assigned_treatment\n",
            "Adjustment Variables: x2\n",
            "Model Fitter: Weighted Logistic Regression\n",
            "\n",
            "## Regression Coefficients & Interpretation\n",
            "              Term      Estimate\n",
            "         Intercept -1.352554e+01\n",
            "assigned_treatment  1.022324e+01\n",
            "                x2  5.721033e-01\n",
            " followup_time_std -5.890204e-24\n",
            "\n",
            "## Model Summary Statistics\n",
            "Number of Observations: 44500\n",
            "\n",
            "## Sample Data\n",
            " id  trial_period  followup_time  outcome   weight  assigned_treatment\n",
            "1.0             0              0      0.0 0.834219                   1\n",
            "1.0             1              1      0.0 0.849393                   1\n",
            "1.0             2              2      0.0 0.862840                   1\n",
            "1.0             3              3      0.0 0.874501                   1\n",
            "1.0             4              4      0.0 0.884416                   1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sakurakano/DataAnalytics/.venv/lib/python3.9/site-packages/statsmodels/base/l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 2 out of 4 parameters\n",
            "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
            "  warnings.warn(message, ConvergenceWarning)\n",
            "/Users/sakurakano/DataAnalytics/.venv/lib/python3.9/site-packages/statsmodels/base/l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
            "  warnings.warn(msg, ConvergenceWarning)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def check_multicollinearity(data, predictors):\n",
        "    \"\"\"\n",
        "    Compute VIF for each predictor to detect collinearity.\n",
        "    \"\"\"\n",
        "    X = data[predictors].dropna()\n",
        "    X = sm.add_constant(X)  \n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = X.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "def fit_outcome_model(trial, outcome_formula, weight_col=\"weight\"):\n",
        "    \"\"\"\n",
        "    Fit a weighted logistic regression model for the outcome using MSM.\n",
        "    \"\"\"\n",
        "    data = trial[\"expanded_data\"].copy()\n",
        "\n",
        "\n",
        "    data[\"followup_time_std\"] = (data[\"followup_time\"] - data[\"followup_time\"].mean()) / data[\"followup_time\"].std()\n",
        "    \n",
        " \n",
        "    required_cols = [\"outcome\", \"assigned_treatment\", \"x2\", \"followup_time_std\", weight_col]\n",
        "    for col in required_cols:\n",
        "        if col not in data.columns:\n",
        "            raise ValueError(f\"Column '{col}' is missing from the dataset.\")\n",
        "\n",
        "    print(\"\\n Checking variation in follow-up time:\")\n",
        "    print(data[\"followup_time_std\"].value_counts().head(10))\n",
        "\n",
        "    print(\"\\n Checking Correlation Between Follow-Up Time and Trial Period:\")\n",
        "    print(data[[\"followup_time_std\"]].corr()) \n",
        "\n",
        "\n",
        "    vif_df = check_multicollinearity(data, [\"x2\", \"followup_time_std\"])\n",
        "    print(\"\\n Updated VIF after standardizing follow-up time:\")\n",
        "    print(vif_df)\n",
        "\n",
        "\n",
        "    try:\n",
        "        model = sm.Logit.from_formula(outcome_formula, data)\n",
        "        result = model.fit_regularized(method='l1', alpha=0.01, disp=False)  \n",
        "        trial[\"outcome_model\"] = result \n",
        "    except Exception as e:\n",
        "        print(\"Model fitting failed:\", e)\n",
        "        raise\n",
        "\n",
        "    return trial\n",
        "\n",
        "def display_outcome_model(trial):\n",
        "    \n",
        "    if \"outcome_model\" not in trial:\n",
        "        raise ValueError(\"Outcome model is missing. Run `fit_outcome_model` first.\")\n",
        "\n",
        "    result = trial[\"outcome_model\"]\n",
        "    data = trial[\"expanded_data\"]\n",
        "\n",
        "    print(\"\\n## Outcome Model Specification\")\n",
        "    print(\"Formula: outcome ~ assigned_treatment + x2 + followup_time_std\")\n",
        "    print(\"Treatment Variable: assigned_treatment\")\n",
        "    print(\"Adjustment Variables: x2\")\n",
        "    print(\"Model Fitter: Weighted Logistic Regression\")\n",
        "\n",
        "\n",
        "    coef_df = pd.DataFrame({\n",
        "        \"Term\": result.params.index,\n",
        "        \"Estimate\": result.params.values\n",
        "    })\n",
        "    print(\"\\n## Regression Coefficients & Interpretation\")\n",
        "    print(coef_df.to_string(index=False))\n",
        "\n",
        "    print(\"\\n## Model Summary Statistics\")\n",
        "    print(f\"Number of Observations: {len(data)}\")\n",
        "\n",
        "\n",
        "    print(\"\\n## Sample Data\")\n",
        "    print(data[[\"id\", \"trial_period\", \"followup_time\", \"outcome\", \"weight\", \"assigned_treatment\"]].head(5).to_string(index=False))\n",
        "\n",
        "\n",
        "outcome_formula = \"outcome ~ assigned_treatment + x2 + followup_time_std\"\n",
        "\n",
        "\n",
        "trial_itt = fit_outcome_model(trial_itt, outcome_formula)\n",
        "trial_pp = fit_outcome_model(trial_pp, outcome_formula)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"#\"*50)\n",
        "print(\"Intention-to-Treat (ITT) Trial Outcome Model\")\n",
        "print(\"#\"*50 + \"\\n\")\n",
        "display_outcome_model(trial_itt)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"#\"*50)\n",
        "print(\"Per-Protocol (PP) Trial Outcome Model\")\n",
        "print(\"#\"*50 + \"\\n\")\n",
        "display_outcome_model(trial_pp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 9: Inference\n",
        "We use the predict() method to estimate survival probabilities or cumulative incidences for different values of assigned_treatment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualization steps:\n",
        "1. Predicting Survival Probabilities\n",
        "- We use predict() to estimate survival for treatment & control groups\n",
        "- Goal is to compare survival over time between treated group and control group.\n",
        "\n",
        "2. Computing Survival Difference\n",
        "- Survival difference = Treated survival - Control survival\n",
        "- Ideally, this should change over time (e.g., a new treatment might improve survival early but have diminishing effects later).\n",
        "\n",
        "3. Visualizing\n",
        "- Confidence Intervals (CI): Shows uncertainty in our estimate.\n",
        "- X-axis: followup time\n",
        "- Y-axis: survival difference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjYbqnMTKqax"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_survival(trial, predict_times=np.arange(0, 11)):\n",
        "    \"\"\"\n",
        "    Predict survival probabilities over follow-up time using the fitted outcome model.\n",
        "    \"\"\"\n",
        "    if \"outcome_model\" not in trial:\n",
        "        raise ValueError(\"Outcome model is missing. Run `fit_outcome_model` first.\")\n",
        "    \n",
        "    model = trial[\"outcome_model\"]\n",
        "    data = trial[\"expanded_data\"].copy()\n",
        "\n",
        "    baseline_data = data[data[\"trial_period\"] == 1].copy()\n",
        "\n",
        "    required_cols = [\"followup_time\", \"assigned_treatment\"]\n",
        "    for col in required_cols:\n",
        "        if col not in baseline_data.columns:\n",
        "            raise ValueError(f\"Column '{col}' is missing from baseline data.\")\n",
        "\n",
        "    survival_preds = []\n",
        "    for t in predict_times:\n",
        "        temp_data = baseline_data.copy()\n",
        "        temp_data[\"followup_time_std\"] = (t - data[\"followup_time\"].mean()) / data[\"followup_time\"].std()\n",
        "\n",
        "        temp_data[\"predicted_prob\"] = model.predict(temp_data)\n",
        "\n",
        "        survival_preds.append(temp_data[[\"followup_time_std\", \"assigned_treatment\", \"predicted_prob\"]])\n",
        "\n",
        "    survival_preds = pd.concat(survival_preds)\n",
        "\n",
        "    mean_survival = survival_preds.groupby([\"followup_time_std\", \"assigned_treatment\"])[\"predicted_prob\"].mean().unstack()\n",
        "    mean_survival[\"survival_diff\"] = mean_survival[1] - mean_survival[0]  \n",
        "\n",
        "    pred_var = np.var(survival_preds[\"predicted_prob\"])\n",
        "    mean_survival[\"lower_ci\"] = mean_survival[\"survival_diff\"] - 1.96 * np.sqrt(pred_var)\n",
        "    mean_survival[\"upper_ci\"] = mean_survival[\"survival_diff\"] + 1.96 * np.sqrt(pred_var)\n",
        "\n",
        "    return mean_survival.reset_index()\n",
        "\n",
        "survival_predictions = predict_survival(trial_itt)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(survival_predictions[\"followup_time_std\"], survival_predictions[\"survival_diff\"], label=\"Survival Difference\", color=\"blue\")\n",
        "plt.fill_between(survival_predictions[\"followup_time_std\"], \n",
        "                 survival_predictions[\"lower_ci\"], \n",
        "                 survival_predictions[\"upper_ci\"], color=\"red\", alpha=0.2, label=\"95% CI\")\n",
        "\n",
        "plt.xlabel(\"Follow-up Time (Standardized)\")\n",
        "plt.ylabel(\"Survival Difference\")\n",
        "plt.title(\"Survival Difference Over Follow-up Time\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Insights\n",
        "\n",
        "Step 9 output shows a constant survial differenceacross follow-up times, meaning the predicted survival probability does not change over time. \n",
        "\n",
        "### Reasons why the model failed to capture any meaningful trend over follow-up time\n",
        "\n",
        "1. Follow-up time was highly correlated with other variables\n",
        "    - Initially, followup_time was highly correlated with trial_period (r â‰ˆ 0.97).\n",
        "    - This means both variables carried almost the same information â†’ causing redundancy in the model.\n",
        "    - When two variables are nearly identical in meaning, the model struggles to determine which one is driving the outcome.\n",
        "\n",
        "2. High VIF in Follow-up Time\n",
        "    - Variance Inflation Factor (VIF) for follow-up time was âˆž (infinity).\n",
        "    - A high VIF means that a variable is strongly linearly dependent on other predictors.\n",
        "    - followup_time was not adding unique information, leading to unstable coefficient estimates.\n",
        "\n",
        "3. Removing Follow-up Time Caused Model Ignoring Time Effect\n",
        "    - To fix the multicollinearity issue, we standardized followup_time (followup_time_std).\n",
        "    - However, this didn't fully fix the problem because:\n",
        "        - We removed trial_period, which was acting as a timeline variable.\n",
        "        - The model still couldn't effectively learn from followup_time_std because its effect on the outcome was already lost.\n",
        "\n",
        "### Interpretation of our failed model\n",
        "-  The model does not recognize any change in survival probability over time.\n",
        "- This results in a flat survival difference curve, meaning the model does not distinguish short-term vs. long-term effects.\n",
        "\n",
        "However, in a well-fitted survival model, we expect:\n",
        "- Survival probability to decrease over time.\n",
        "- Treatment differences to appear over time.\n",
        "- Confidence intervals to widen as uncertainty grows.\n",
        "\n",
        "### Future improvement\n",
        "- Adding a different time-based predictor.\n",
        "- Using a Cox model instead of logistic regression.\n",
        "- Checking whether raw survival rates actually change over time.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
